%!TEX root = ../main.tex
%-------------------------------------------------------------------------------
\section{Improvements}\label{Computation}
%-------------------------------------------------------------------------------
The implementation and analysis of this class of models entails several computational challenges. Among them integration of a high-dimensional non-differentiable function, large-scale global optimization of a noisy and non-smooth criterion function, function approximation, and parallelization strategies. We briefly outline each of them.
%-------------------------------------------------------------------------------
\subsection{Numerical integration} We draw on the extensive literature in applied math on numerical integration \citep{Davis.2007}. To clarify the structure of the integral determining the future value of a state, it is useful to consider the optimality equation in a generic time period $t$. This allows to focus on action-specific rewards instead of future values. Let $v^{\pi}_{t}(s_t, a_t)$ denote the action-specific value function of choosing action $a$ in state $s$ while continuing with the optimal policy going forward.
but sticking to the optimal policy $\pi^*$ going forward.
%
\begin{align}
v^{\pi}_{t}(s_t, a_t) & = u(s_t, a_t) + \delta\,\E_{s_t} \left[\left.v^{\pi^*}_{t + 1}(s_{t + 1})\,\right\vert\,\mathcal{I}_t\,\right] \\
& =  u(s_t, a_t) + \delta\, \int_S v^{\pi^*}_{t + 1}(s_{t + 1})\, \diff p_t(a_t, s_t)\\
& =  u(s_t, a_t) + \delta\, \underbrace{\int_S \max_{a \in A}\bigg\{v^\pi_{t + 1}(s_{t + 1}, a_{t + 1})\bigg\}\diff p_t(a_t, s_t)}_{\mathcal{I}(a_{t + 1})}.
\end{align}

\noindent The evaluation of such an integral is required millions of times during the backward induction procedure. The current practice is to implement a random Monte Carlo integration which introduces considerable numerical error and computational instabilities \citep{Judd.2011}.\\

\noindent Let's consider an atemporal version of the typical integral from \citet{Keane.1997}. In their model, individuals can choose among five alternatives. Each of the alternative-specific rewards is in part determined by a random continuous state variable that follows a normal distribution which happens to be unobserved. The transition of all observable state variables is deterministic. This results in a five-dimensional integrals the dimensionality is determined by the random state variables. The integral takes the following form:
%
\begin{align*}
   \int_{\epsilon}\, \max_{a\in A} \bigg\{v_{t + 1}^\pi(x_{t + 1}, \epsilon, a)\}\bigg\} \phi_{\mu, \Sigma}(\epsilon) \diff\epsilon.
\end{align*}

\noindent where $\epsilon = (\epsilon_1, \dots, \epsilon_5) \sim \mathcal{N}(\mu, \Sigma)\,$ follows a multivariate normal distribution with mean $\mu \in \mathbb{R}^{5}$, covariance matrix $ \Sigma \in \mathbb{R}^{5 \times 5}$, and probability density function $\phi_{\mu, \Sigma}$. A key features of this integral is the lack of general separability between the random and deterministic state variables. This makes the closed-form solutions impossible even under suitable distributional assumptions \citep{McFadden.1978,Rust.1987}.
%-------------------------------------------------------------------------------
\subsection{Global optimization}
\begin{itemize}
\item This issue is under active investigation in our group and this section will be fleshed out further as our work progresses. We draw on the specialized literature on global optimization to improve the reliability of calibrations \citep{Locatelli.2013}. Depending on the calibration procedure special challenges arise. Likelihood-based estimation requires smoothing of the choice probabilities, while simulation-based calibration requires the application of noisy function optimization. The further development of our groups optimization toolbox \verb+estimagic+ \citep{Gabler.2019} is part of this project.
\end{itemize}
%-------------------------------------------------------------------------------
\subsection{Miscellaneous} Other areas of improvement that require our future attention is the approximate solution of the model using function approximation techniques and the issue of using massive parallelism for the analysis of the models.
