%!TEX root = ../main.tex
%-------------------------------------------------------------------------------
\section{Computational challenges}\label{Computation}
%-------------------------------------------------------------------------------
The implementation and analysis of this class of models entails several computational challenges. Among them integration of a high-dimensional non-differentiable function, large-scale global optimization of a noisy and non-smooth criterion function, function approximation, and parallelization strategies. We briefly outline each of them. 
%-------------------------------------------------------------------------------
\paragraph{Structure of integral} To clarify the structure of the integral determining the future value of a state, it is useful to consider the optimality equation in the second to last period. This allows to focus on action-specific rewards instead of future values. Let $v^{\pi}_{T-1}(s_t, a_t)$ denote the action-specific value function of choosing action $a$ in state $s$ while continuing with the optimal policy going forward.
but sticking to the optimal policy $\pi^*$ going forward.
%
\begin{align}
v^{\pi}_{t}(s_t, a_t) & = u(s_t, a_t) + \delta\,\E_{s_t} \left[v^{\pi^*}_{t + 1}(s_{t + 1})\right] \\
& =  u(s_t, a_t) + \delta\, \int_S v^{\pi^*}_{t + 1}(s_{t + 1})\, \diff p_t(a_t, s_t)\\
& =  u(s_t, a_t) + \delta\, \underbrace{\int_S \max_{a \in A}\bigg\{v^\pi_{t + 1}(s_{t + 1}, a)\bigg\}\diff p_t(a_t, s_t)}_{\mathcal{I}(a_{t + 1})}.
\end{align}

The evaluation of such an integral is required millions of times during the backward induction procedure. The current practice is to implement a random Monte Carlo integration which introduces considerable numerical error and computational instabilities \citep{Judd.2011}.\\

Let's consider an atemporal version of the typical integral from \citet{Keane.1997}. In their model, individuals can choose among five alternatives. Each of the alternative-specific rewards is in part determined by a random continuous state variable that follows a normal distribution which happens to be unobserved. The transition of all observable state variables is deterministic. This results in a five-dimensional integral $\mathcal{I}(a^\prime)$ as the dimensionality is determined by the random state variables. The integral takes the following form:
%
\begin{align*}
\mathcal{I}(a) = \int_{\epsilon}\, \max_{a\in A} \bigg\{v^\pi_{t + 1}(x, \epsilon, a)\}\bigg\} \phi_{\mu, \Sigma}(\epsilon) \diff\epsilon.
\end{align*}

where $\epsilon = (\epsilon_1, \dots, \epsilon_5) \sim \mathcal{N}(\mu, \Sigma)\,$ follows a multivariate normal distribution with mean $\mu \in \mathbb{R}^{5}$, covariance matrix $ \Sigma \in \mathbb{R}^{5 \times 5}$, and probability density function $\phi_{\mu, \Sigma}(\epsilon)$. A key features of this integral is the lack of general separability between the random and deterministic state variables. This makes the closed-form solutions impossible even under suitable distributional assumptions \citep{McFadden.1978,Rust.1987}.

\paragraph{Global optimization} $\hdots$


\begin{itemize}
  \item \textbf{Likelihood-based estimation} This approach requires smoothing of the choice probabilities.

  \begin{align*}
    p_t(d_{it} \mid x_{it}, \theta) = \int \Ind [ \delta(x_{it}, \epsilon_{it}, \theta) = a_{it} ] g(\epsilon) \diff \epsilon
  \end{align*}

  \item \textbf{Simulation-based estimation} This approach requires the optimization of a noisy function.


\end{itemize}

\paragraph{Function approximation} $\hdots$

\paragraph{Parallelization} $\hdots$
