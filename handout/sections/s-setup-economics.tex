%!TEX root = ../main.tex
%-------------------------------------------------------------------------------
\subsection{Economic framework}
%-------------------------------------------------------------------------------
\paragraph{Basic setup} EKW models describe sequential decision-making under risk \citep{Machina.2014,Gilboa.2009}. At time $t = 1, \hdots, T$ each individual observes the state of the economic environment $s_t\in S$ and chooses an action $a_t$ from the set of admissible actions $\mathcal{A}$. The decision has two consequences: an individual receives an immediate reward $r(s_t, a_t)$ and the economy evolves to a new state $s_{t + 1}$. The transition from $s_t$ to $s_{t + 1}$ is affected by the action.  Individuals are forward-looking, thus they do not simply choose the alternative with the highest immediate reward. Instead, they take the future consequences of their current action into account.

\paragraph{Decision rule} A policy $\pi \equiv(a^\pi_1(s), \hdots, a^\pi_T(s))$ provides the individual with a prescription for choosing an action in any possible future state, where $a^\pi_t(s)$ specifies the action at a particular time $t$ for any possible state $s$ under $\pi$. It is a sequence of decision rules and its implementation generates a sequence of rewards.  The evolution of states over time is at least partly unknown and individuals use models about their economic environment to inform their subjective beliefs about the future. For a given model, individuals thus face risk as each induces a unique objective transition probability distribution $p_t(s_t, a_t)$ for the evolution of state $s_t$ to $s_{t + 1}$ that depends on the action $a_t$. Individuals have rational expectations \citep{Muth.1961,Lucas.1972} so their subjective beliefs correspond to the objective transition probabilities.

\paragraph{Timing of events} Figure \ref{Timing} depicts the timing of events in the model for two generic time periods. At the beginning of time $t$ an individual fully learns about the immediate reward of each alternative, chooses one of them, and receives its immediate reward. Then the state evolves from $s_t$ to $s_{t + 1}$ and the process is repeated in $t + 1$.
%
\begin{figure}\caption{Timing of events}\label{Timing}\vspace{1.0cm}\centering
\input{material/fig-timing.tex}
\end{figure}
%
\paragraph{Decision theory} Individuals make their decisions facing risk and in this case, there is a consensus that rational choices are expressed by the maximization of their expected total discounted rewards. An exponential discount factor $0 < \delta < 1$ captures a preference for immediate over future rewards and ensures dynamic consistency of preferences as the individual's future actions agree with the planned-for contingencies. Beliefs are updated according to Bayes's rule.

Equation (\ref{Objective Risk}) provides the formal representation of the individual's objective. Given an initial state $s_1$, individuals seek to implement the policy $\pi$ from the set of all possible policies $\Pi$ that maximizes the expected total discounted rewards over all $T$ decision periods given the information $\mathcal{I}_1$ available.
%
\begin{align}\label{Objective Risk}
\max_{\pi \in\Pi} \E_{s_1}^\pi\left[\left.\sum^{T}_{t = 1}  \delta^{t - 1} r(s_t, a^\pi_t(s_t))\,\right\vert\,\mathcal{I}_1\,\right]
\end{align}
%
The superscript of the expectation emphasizes that each policy $\pi$ induces a different unique probability distribution over the sequences of rewards.
