%!TEX root = ../main.tex
%-------------------------------------------------------------------------------
\subsection{Economic framework}
%-------------------------------------------------------------------------------
EKW models describe sequential decision-making under uncertainty \citep{Gilboa.2009,Machina.2014}. At time $t = 1, \hdots, T$ each individual observes the state of the economic environment $s_t\in S$ and chooses an action $a_t$ from the set of admissible actions $\mathcal{A}$. The decision has two consequences: an individual receives an immediate reward $r_t(s_t, a_t)$ and the economy evolves to a new state $s_{t + 1}$. The transition from $s_t$ to $s_{t + 1}$ affected by the action but remains uncertain. Individuals are forward-looking, thus they do not simply choose the alternative with the highest immediate reward. Instead, they take the future consequences of their current action into account.\\

\noindent A policy $\pi \equiv(a^\pi_1(s), \hdots, a^\pi_T(s))$ provides the individual with a prescription for choosing an action in any possible future state, where the decision rule $a^\pi_t(s)$ specifies the action at a particular time $t$ for any possible state $s$ under $\pi$. It is a sequence of decision rules and its implementation generates a sequence of rewards.  As the evolution of states over time is uncertain, individuals use a model about their economic environment to inform their subjective beliefs about the future. For a given model, individuals thus face risk as each induces a unique objective transition probability distribution $p_t(s_t, a_t)$ for the evolution of state $s_t$ to $s_{t + 1}$ that depends on the action $a_t$. Individuals have rational expectations \citep{Lucas.1972,Muth.1961} so their subjective beliefs correspond to the objective transition probabilities.\\

\noindent Figure \ref{Timing} depicts the timing of events in the model for two generic time periods. At the beginning of period $t$ an individual fully learns about the immediate reward of each alternative, chooses one of them, and receives its immediate reward. Then the state evolves from $s_t$ to $s_{t + 1}$ and the process is repeated in $t + 1$.
%
\begin{figure}\caption{Timing of events}\label{Timing}\vspace{1.0cm}\centering
\input{material/fig-timing.tex}
\end{figure}
%
\noindent Individuals make their decisions facing uncertainty and they maximize the expected total discounted rewards. An exponential discount factor $0 < \delta < 1$ parameterizes their time preference and captures a taste for immediate over future rewards.\\

\noindent Equation (\ref{Objective Risk}) provides the formal representation of the individual's objective. Given an initial state $s_1$, individuals seek to implement the policy $\pi$ from the set of all possible policies $\Pi$ that maximizes the expected total discounted rewards over all $T$ decision periods given the information $\mathcal{I}_1$ available in the first period.
%
\begin{align}\label{Objective Risk}
\max_{\pi \in\Pi} \E_{s_1}^\pi\left[\left.\sum^{T}_{t = 1}  \delta^{t - 1} r_t(s_t, a^\pi_t(s_t))\,\right\vert\,\mathcal{I}_1\,\right]
\end{align}
%
The superscript of the expectation emphasizes that each policy $\pi$ induces a different unique probability distribution over the sequences of rewards. Note that in slight abuse of notation $s_{t + 1}$ is a random variable given the information available at $\mathcal{I}_t$ and $a^\pi_{t}(s_{t})$ denotes the actual action that an individual chooses in time $t$ if they encounter $s_{t}$ and follow policy $\pi$.
