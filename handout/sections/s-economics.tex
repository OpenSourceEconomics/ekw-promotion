%!TEX root = ../main.tex
%-------------------------------------------------------------------------------
\section{Economic motivation}
%-------------------------------------------------------------------------------
\paragraph{Basic setup} At time $t = 1, \hdots, T$ each individual observes the state of the economic environment $s_t\in S$ and chooses an action $a_t$ from the set of admissible actions $\mathcal{A}$. The decision has two consequences: an individual receives an immediate utility $u(s_t, a_t)$ and the economy evolves to a new state $s_{t + 1}$. The transition from $s_t$ to $s_{t + 1}$ is affected by the action.  Individuals are forward-looking, thus they do not simply choose the alternative with the highest immediate utility. Instead, they take the future consequences of their current action into account.

\paragraph{Decision rule} A policy $\pi \equiv(a^\pi_1(s), \hdots, a^\pi_T(s))$ provides the individual with a prescription for choosing an action in any possible future state, where $a^\pi_t(s)$ specifies the action at a particular time $t$ for any possible state under $\pi$. It is a sequence of decision rules and its implementation generates a sequence of utilities.  The evolution of states over time is at least partly unknown as future utilities depend on, for example, shocks to preferences. Individuals use models about their economic environment to inform their beliefs about the future. For a given model, individuals thus face risk as each induces a unique objective transition probability distribution $p_t(s_t, a_t)$ for the evolution of state $s_t$ to $s_{t + 1}$ that depends on the action $a_t$.

\paragraph{Timing of events} Figure \ref{Timing} depicts the timing of events in the model for two generic time periods. At the beginning of time $t$ an individual fully learns about the immediate utility of each alternative, chooses one of them, and receives its immediate utility. Then the state evolves from $s_t$ to $s_{t + 1}$ and the process is repeated in $t + 1$.
%
\begin{figure}\caption{Timing of events}\label{Timing}\vspace{1.0cm}\centering
\input{material/fig-timing.tex}
\end{figure}
%
\paragraph{Decision theory} Individuals make their decisions facing risk and have rational expectations \citep{Muth.1961,Lucas.1972} as their model about the future also turns out to be true. In this case, there is a consensus that rational choices are expressed by expected utility preferences \citep{Bernoulli.1738,Neumann.1944,Neumann.1947}.

\paragraph{Formalization} Individuals maximize their expected total discounted utility \citep{Samuelson.1937,Koopmans.1960}. A constant discount factor ensures dynamic consistency of preferences as the individual's future actions agree with the planned-for contingencies. Beliefs are updated according to Bayes's rule.\footnote{See \citet{Frederick.2002} for a critical review of the literature on time discounting and time preference. \citet{Fang.2009}, \citet{Fang.2015}, and \citet{Chan.2017} are examples of hyperbolic discounting and thus potentially time-inconsistent preferences in settings similar to the one discussed here.}\\

Equation (\ref{Objective Risk}) provides the formal representation of the individual's objective. Given an initial state $s_1$, individuals seek to implement the optimal policy $\pi^*$ from the set of all possible policies $\Pi$ that maximizes the expected total discounted utility over all $T$ decision periods given the information available at the time $\mathcal{I}_1$.
%
\begin{align}\label{Objective Risk}
\max_{\pi \in\Pi} \E_{s_1}^\pi\left[\left.\sum^{T}_{t = 1}  \delta^{t - 1} u(s_t, a^\pi_t(s_t)) \right\vert\,\mathcal{I}_1\,\right]
\end{align}
%
The exponential discount factor $0 < \delta < 1$ captures a preference for immediate over future utility. The superscript of the expectation emphasizes that each policy $\pi$ induces a different unique probability distribution over the sequences of utilities.
